# ğŸš€ Tech Challenge Fase 2 - ToggleMaster Microservices

[![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)](https://aws.amazon.com/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)

> âš ï¸ **PROJETO DIDÃTICO** - Este projeto foi desenvolvido como parte do Tech Challenge Fase 2 da PÃ³s-Tech FIAP em Arquitetura Cloud e DevOps.

## ğŸ“‹ Sobre o Projeto

Este projeto representa a evoluÃ§Ã£o do ToggleMaster, uma plataforma de Feature Flags, migrando de uma arquitetura monolÃ­tica para microsserviÃ§os distribuÃ­dos orquestrados pelo Kubernetes (AWS EKS).

### ğŸ“ CrÃ©ditos

| Componente | Autor |
|------------|-------|
| CÃ³digo dos 5 microsserviÃ§os (Go/Python) | Professor da FIAP |
| Dockerfiles (multi-stage builds) | Vitor Gabriel |
| Docker Compose | Vitor Gabriel |
| Manifestos Kubernetes (deployments, services, secrets, configmaps, ingress, hpa) | Vitor Gabriel |
| Infraestrutura AWS (EKS, RDS, ElastiCache, DynamoDB, SQS, ECR) | Vitor Gabriel |

## ğŸ—ï¸ Arquitetura

O sistema Ã© composto por 5 microsserviÃ§os:

| ServiÃ§o | Linguagem | Banco de Dados | Porta | DescriÃ§Ã£o |
|---------|-----------|----------------|-------|-----------|
| **auth-service** | Go | PostgreSQL | 8001 | Gerencia chaves de API e autenticaÃ§Ã£o |
| **flag-service** | Python | PostgreSQL | 8002 | CRUD das definiÃ§Ãµes de feature flags |
| **targeting-service** | Python | PostgreSQL | 8003 | Gerencia regras de segmentaÃ§Ã£o |
| **evaluation-service** | Go | Redis | 8004 | Hot path de alta performance (true/false) |
| **analytics-service** | Python | DynamoDB + SQS | 8005 | Consome eventos e salva dados de anÃ¡lise |

### ğŸ“Š Diagrama da Arquitetura

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚            AWS Cloud                     â”‚
                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                                    â”‚  â”‚     Application Load Balancer       â”‚â”‚
                                    â”‚  â”‚        (Nginx Ingress)              â”‚â”‚
                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                                    â”‚                 â”‚                        â”‚
                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                                    â”‚  â”‚         Amazon EKS Cluster          â”‚â”‚
                                    â”‚  â”‚                                      â”‚â”‚
                                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚â”‚
                                    â”‚  â”‚  â”‚  auth   â”‚  â”‚  flag   â”‚           â”‚â”‚
                                    â”‚  â”‚  â”‚ service â”‚  â”‚ service â”‚           â”‚â”‚
                                    â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚â”‚
                                    â”‚  â”‚       â”‚            â”‚                 â”‚â”‚
                                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”           â”‚â”‚
                                    â”‚  â”‚  â”‚targetingâ”‚  â”‚evaluate â”‚           â”‚â”‚
                                    â”‚  â”‚  â”‚ service â”‚  â”‚ service â”‚           â”‚â”‚
                                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚â”‚
                                    â”‚  â”‚                    â”‚                 â”‚â”‚
                                    â”‚  â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”        â”‚â”‚
                                    â”‚  â”‚            â”‚   analytics   â”‚        â”‚â”‚
                                    â”‚  â”‚            â”‚    service    â”‚        â”‚â”‚
                                    â”‚  â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚â”‚
                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                                    â”‚                                          â”‚
                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
                                    â”‚  â”‚ RDS        â”‚ â”‚ElastiCache â”‚          â”‚
                                    â”‚  â”‚ PostgreSQL â”‚ â”‚   Redis    â”‚          â”‚
                                    â”‚  â”‚ (3 inst.)  â”‚ â”‚            â”‚          â”‚
                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                                    â”‚                                          â”‚
                                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
                                    â”‚  â”‚  DynamoDB  â”‚ â”‚    SQS     â”‚          â”‚
                                    â”‚  â”‚            â”‚ â”‚            â”‚          â”‚
                                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **OrquestraÃ§Ã£o:** Kubernetes (AWS EKS)
- **ContainerizaÃ§Ã£o:** Docker com multi-stage builds
- **Banco de Dados:** PostgreSQL (AWS RDS), Redis (AWS ElastiCache), DynamoDB
- **Mensageria:** AWS SQS
- **Load Balancer:** Nginx Ingress Controller
- **Escalabilidade:** Horizontal Pod Autoscaler (HPA)
- **Registry:** AWS ECR

## ğŸ“ Estrutura do Projeto

```
tech-challenge-fase2/
â”œâ”€â”€ analytics-service/       # MicrosserviÃ§o de analytics (Python)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ auth-service/            # MicrosserviÃ§o de autenticaÃ§Ã£o (Go)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.go
â”‚   â””â”€â”€ db/init.sql
â”œâ”€â”€ evaluation-service/      # MicrosserviÃ§o de avaliaÃ§Ã£o (Go)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ main.go
â”œâ”€â”€ flag-service/            # MicrosserviÃ§o de flags (Python)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ db/init.sql
â”œâ”€â”€ targeting-service/       # MicrosserviÃ§o de targeting (Python)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ db/init.sql
â”œâ”€â”€ k8s/                     # Manifestos Kubernetes
â”‚   â”œâ”€â”€ namespaces/
â”‚   â”œâ”€â”€ secrets/
â”‚   â”œâ”€â”€ configmaps/
â”‚   â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ingress/
â”‚   â””â”€â”€ hpa/
â”œâ”€â”€ docker-compose.yml       # Compose para ambiente local
â”œâ”€â”€ init-shared-dbs.sh       # Script de init dos bancos
â””â”€â”€ README.md
```

---

# ğŸš€ Como Executar o Projeto

## OpÃ§Ã£o 1: Ambiente Local (Docker Compose)

### PrÃ©-requisitos
- Docker e Docker Compose instalados
- Git

### Passo a Passo

**1. Clone o repositÃ³rio:**
```bash
git clone https://github.com/vitorrgabriell/tech-challenge-fase-2-fiap.git
cd tech-challenge-fase-2-fiap
```

**2. Suba os containers:**
```bash
docker-compose up --build
```

**3. Aguarde todos os 10 containers subirem:**
- 5 microsserviÃ§os
- 2 PostgreSQL
- 1 Redis
- 1 DynamoDB Local
- 1 LocalStack (SQS)

**4. Teste os health checks:**
```bash
curl http://localhost:8001/health  # auth-service
curl http://localhost:8002/health  # flag-service
curl http://localhost:8003/health  # targeting-service
curl http://localhost:8004/health  # evaluation-service
curl http://localhost:8005/health  # analytics-service
```

**5. Crie uma chave de API:**
```bash
curl -X POST http://localhost:8001/admin/keys \
-H "Content-Type: application/json" \
-H "Authorization: Bearer admin-secreto-123" \
-d '{"name": "minha-chave"}'
```

**6. Use a chave para acessar os outros serviÃ§os:**
```bash
curl http://localhost:8002/flags \
-H "Authorization: Bearer <sua-chave-api>"
```

---

## OpÃ§Ã£o 2: Ambiente AWS (EKS)

### PrÃ©-requisitos
- Conta AWS (Academy ou pessoal)
- AWS CLI configurado
- kubectl instalado
- Docker instalado

### Passo 1: Criar Infraestrutura AWS

**1.1. Criar repositÃ³rios no ECR:**
```bash
# Criar 5 repositÃ³rios
aws ecr create-repository --repository-name tech-challenge/auth-service
aws ecr create-repository --repository-name tech-challenge/flag-service
aws ecr create-repository --repository-name tech-challenge/targeting-service
aws ecr create-repository --repository-name tech-challenge/evaluation-service
aws ecr create-repository --repository-name tech-challenge/analytics-service
```

**1.2. Criar recursos via Console AWS:**
- 3x RDS PostgreSQL (auth-db, flag-db, targeting-db)
- 1x ElastiCache Redis
- 1x Tabela DynamoDB
- 1x Fila SQS
- 1x Cluster EKS com Node Group

### Passo 2: Build e Push das Imagens

**2.1. Login no ECR:**
```bash
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account-id>.dkr.ecr.us-east-1.amazonaws.com
```

**2.2. Build e push de cada serviÃ§o:**
```bash
# Exemplo para auth-service (repetir para os outros 4)
docker build -t <account-id>.dkr.ecr.us-east-1.amazonaws.com/tech-challenge/auth-service:latest ./auth-service
docker push <account-id>.dkr.ecr.us-east-1.amazonaws.com/tech-challenge/auth-service:latest
```

### Passo 3: Configurar kubectl

```bash
aws eks update-kubeconfig --region us-east-1 --name tech-challenge-cluster
kubectl get nodes  # Verificar conexÃ£o
```

### Passo 4: Deploy no Kubernetes

**4.1. Aplicar os manifestos na ordem:**
```bash
# Namespace
kubectl apply -f k8s/namespaces/

# Secrets (editar com seus endpoints RDS/Redis/SQS)
kubectl apply -f k8s/secrets/

# ConfigMaps
kubectl apply -f k8s/configmaps/

# Deployments
kubectl apply -f k8s/deployments/

# Services
kubectl apply -f k8s/services/

# Ingress
kubectl apply -f k8s/ingress/

# HPAs
kubectl apply -f k8s/hpa/
```

**4.2. Instalar Nginx Ingress Controller:**
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/aws/deploy.yaml
```

**4.3. Inicializar tabelas nos bancos RDS:**
```bash
# Conectar em cada RDS e executar os scripts db/init.sql
kubectl run psql-client --rm -it --restart=Never -n tech-challenge \
  --image=postgres:15 \
  --env="PGPASSWORD=<senha>" \
  -- psql -h <endpoint-rds> -U postgres -d postgres
```

### Passo 5: Verificar o Deploy

```bash
# Ver pods
kubectl get pods -n tech-challenge

# Ver services
kubectl get svc -n tech-challenge

# Ver HPAs
kubectl get hpa -n tech-challenge

# Pegar URL do Load Balancer
kubectl get svc -n ingress-nginx
```

### Passo 6: Testar os Endpoints

```bash
# Health checks
curl http://<load-balancer-url>/auth/health
curl http://<load-balancer-url>/flags/health
curl http://<load-balancer-url>/targeting/health
curl http://<load-balancer-url>/evaluate/health
curl http://<load-balancer-url>/analytics/health

# Criar chave de API
curl -X POST http://<load-balancer-url>/auth/admin/keys \
-H "Content-Type: application/json" \
-H "Authorization: Bearer <master-key>" \
-d '{"name": "minha-chave"}'
```

---

## ğŸ“ˆ Testando a Escalabilidade (HPA)

**1. Instale o hey (ferramenta de load testing):**
```bash
sudo apt install hey -y
```

**2. Gere carga no evaluation-service:**
```bash
hey -z 120s -c 200 http://<load-balancer-url>/evaluate/health
```

**3. Em outro terminal, monitore o HPA:**
```bash
kubectl get hpa -n tech-challenge -w
```

VocÃª verÃ¡ o HPA aumentar o nÃºmero de rÃ©plicas quando a CPU ultrapassar 70%.

---

## ğŸ”— Endpoints da API

| ServiÃ§o | Rota Local | Rota AWS (via Ingress) |
|---------|------------|------------------------|
| auth-service | `localhost:8001/*` | `/auth/*` |
| flag-service | `localhost:8002/*` | `/flags/*` |
| targeting-service | `localhost:8003/*` | `/targeting/*` |
| evaluation-service | `localhost:8004/*` | `/evaluate/*` |
| analytics-service | `localhost:8005/*` | `/analytics/*` |

---

## ğŸ“ VariÃ¡veis de Ambiente Importantes

| VariÃ¡vel | ServiÃ§o | DescriÃ§Ã£o |
|----------|---------|-----------|
| `DATABASE_URL` | auth, flag, targeting | Connection string PostgreSQL |
| `MASTER_KEY` | auth | Chave mestra para criar API keys |
| `AUTH_SERVICE_URL` | flag, targeting | URL do auth-service |
| `REDIS_URL` | evaluation | Connection string Redis |
| `AWS_SQS_URL` | evaluation, analytics | URL da fila SQS |
| `AWS_DYNAMODB_TABLE` | analytics | Nome da tabela DynamoDB |
| `AWS_REGION` | evaluation, analytics | RegiÃ£o AWS |

---

## ğŸ‘¨â€ğŸ’» Autores

**Vitor Gabriel de Almeida, Aleff Silva**
- PÃ³s-Tech FIAP - Arquitetura Cloud e DevOps
- Tech Challenge Fase 2

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© apenas para fins educacionais como parte do programa de pÃ³s-graduaÃ§Ã£o da FIAP.